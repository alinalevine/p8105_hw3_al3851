---
title: "p8105_hw3_al3851.Rmd"
output: github_document
---

#Problem 1

```{r}
library(p8105.datasets)
library(tidyverse)
library(ggplot2)
library(tidyverse)
```


##Data Cleaning
```{r}


brfss_df = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Excellent", "Good", "Poor", "Very good", "Fair")) %>%
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>%
  rename("state" = locationabbr)


```

#locations and observations per state

```{r}
locations_sum_df = brfss_df %>%
  group_by(state) %>%
  distinct(locationdesc, keep.all = TRUE) %>%
  summarize(n_locations = n())
  
filter(locations_sum_df, n_locations == 7)


```
CT, MT, NH, NM, OR, TN, and Utah all had responses from 7 locations. 7 locations was the mode of the number of locations per state. 

#Spaghetti Plot

```{r}
locations_df = brfss_df %>%
  group_by(state, year) %>%
  distinct(locationdesc, .keep_all = TRUE) %>%
  summarize(n_observations = n())

ggplot(locations_df, aes(x = year, y = n_observations, color = state)) +
  geom_line() +
  labs(title = "Locations Per State From 2002-2010 by State",
       x = "Year", 
       y = "Number of Locations") +
  scale_color_hue(name = "State")
  


```

This Spaghetti Plot shows that Florida was an outlier in the number of locations in 2007 and 2010, when there were huge jumps in the number of locations reporting in Florida.


#Table

```{r}

brfss_excellent_tab = brfss_df %>%
  filter(year %in% c(2002,2006, 2010), state == "NY", response == "Excellent") %>%
  group_by(year) %>%
  summarize(mean = mean(data_value), sd = sd(data_value))
  
  
```

The mean proportion of excellent responses decreased from 2002 to 2006, but then it stayed constant. 


Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.


#Average Proportion
```{r}

brfss_prop_av = brfss_df %>%
  group_by(year, state, response) %>%
  summarize(mean_prop = mean(data_value))

ggplot(brfss_prop_av, aes( x = year, y = mean_prop, color = state)) +
  geom_line() +
  facet_grid(~response)

```



#Problem 2

```{r}

instacart_df = instacart


```

There are `r nrow(instacart_df)` rows and `r ncol(instacart_df)` columns. Each observation is identified by the columns order_id and product_id, so each observation is a particular order of a particular product. Some key variables give information about when an order was made. For example , there is a variable for the day of the week, the hour of the day, as well as the number of days since the last order, for each product in an order. Aside from information about order timing, there are variables about the product. For example, one variable gives the name of the product and another gives the department of the product. 

```{r}

n_aisles = length(unique(instacart$aisle))

aisle_table = instacart_df %>%
  group_by(aisle_id) %>%
  mutate(n_items = n()) %>%
  distinct(aisle_id, .keep_all = TRUE)

aisle_table_top = aisle_table %>%
  arrange(desc(n_items))
  

ggplot(aisle_table, aes(x = reorder(aisle,n_items), y = n_items, color = department)) +
  geom_point(stat = "identity") + 
  geom_text_repel(data = rbind(head(aisle_table_top,10), tail(aisle_table_top, 10)), aes(x = aisle, y = n_items, label = aisle)) +
  theme(legend.position="bottom")

```

There are `r n_aisles` aisles. 


```{r}

item_count = instacart_df %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(product_id) %>%
  mutate(product_count = n()) %>%
  ungroup() %>%
  group_by(aisle) %>%
  filter(product_count == max(product_count)) %>%
  distinct(product_id, .keep_all = TRUE) %>%
  select(aisle, product_name, product_count)

```
Organic baby spinach is the most popular item of these most popular items in these three isles. 

```{r}

mean_hour_df = instacart_df %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  mutate(order_dow = as.character(order_dow)) %>%
  mutate(order_dow = recode(order_dow, "0" = "Sunday", "1" = "Monday", "2" = "Tuesday", "3" = "Wednesday", "4" = "Thursday", "5" = "Friday", "6" = "Saturday")) %>%
  spread(key = order_dow, value = mean_hour)

rbind(mean_hour_df$order_dow, mean_hour_df$mean_hour)

mean_hour_switch_df = as.tibble(mean_hour_df$mean_hour)
colnames(mean_hour_switch_df) = mean_hour_df$order_dow

```

The mean hour for every day of the week is in the early afternoon.



#Problem 3


#Data Cleaning
```{r}
ny_noaa_df = ny_noaa %>%
  mutate(year = lubridate::year(date),
         month = lubridate::month(date),
         day = lubridate::day(date)) %>%
  mutate(tmin = as.numeric(tmin)/10, tmax = as.numeric(tmax)/10) %>%
  mutate(snwd = (as.numeric(snwd)/10)/2.54, snow = (as.numeric(snow)/10)/2.54) %>%
  mutate(prcp = (as.numeric(prcp)/100)/2.54)

  


```
The ny_noaa dataframe is `r nrow(ny_noaa_df)' rows by 'r ncol(ny_noaa_df)`. The key variables are the station identification number, the date the weather was recorded, the precipitation (inches) recorded, snow depth (inches) recorded, snowfall recorded (inches), minimum temperature(degrees celsius) and maximum temperature (degrees celsisus). The fact that there is so much missing data may negatively affect any analysis, since so many stations will be unrepresented in plots and calculations for estimates. For example, if data is missing from stations that get very hot, estimates for mean maximum temperature will be too low. 


#Average Maximum Temperatures Per Station

I am grouping by station id, year, and month to get the average maximum temperature for each station in each year in both the months july and january
```{r}

average_max_df = ny_noaa_df %>%
  filter(month %in% c(1,7)) %>%
  select(id, month, year, tmax) %>%
  group_by(id, year, month) %>%
  summarize(average_max = mean(tmax, na.rm = TRUE)) %>%
  mutate(month = as.character(month)) %>%
  mutate(month = recode(month, "1" = "January", "7" = "July"))

  ggplot(average_max_df, aes(x = year, y = average_max, fill = id)) +
    geom_point() +
    facet_grid(~month)
    

```





